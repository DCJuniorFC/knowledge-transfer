{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "> *It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience*.\n",
    "\n",
    "[*often quoted as ‚ÄòEverything should be made as simple as possible, but not simpler‚Äô*, *‚ÄòOn the Method of Theoretical Physics‚Äô, lecture delivered at Oxford, 10 June 1933*](https://www.oxfordreference.com/view/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00003988#:~:text=It%20can%20scarcely%20be%20denied,a%20single%20datum%20of%20experience.&text=The%20eternal%20mystery%20of%20the%20world%20is%20its%20comprehensibility%E2%80%A6)\n",
    "\n",
    " Alguns padr√µes de projeto de solu√ß√£o de competi√ß√µes que o NIASIA identificou at√© agora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um bom resumo deste notebook talvez seja [este post no blog do Emmanuel Ameisen](https://mlpowered.com/posts/start-with-a-stupid-model/), autor do livro 'Building Machine Learning Powered Applications: Going from Idea to Product'.\n",
    "\n",
    "Neste notebook apresentamos argumentos e uma metodologia de errar r√°pido para conseguir acertar em competi√ß√µes de Intelig√™ncia Artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse notebook o foco n√£o ser√° em aprofundar em ideias ou c√≥digos, nem na valida√ß√£o matem√°tica das propostas feitas aqui. Ao contr√°rio, aqui ser√£o apresentados exemplos de como muitos livros, autores e Kagglers resolvem problemas de IA e atingem performances iguais ou acima do estado da arte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolvendo problemas com IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na maioria dos livros, cursos e at√© frameworks de implementa√ß√£o de solu√ß√µes em IA, discute-se uma vis√£o geral de como resolver problemas com IA. Essencialmente, modelos de aprendizado de m√°quina s√£o m√©todos matem√°ticos (frequentemente com forte embasamento estat√≠stico) que tomam entradas num√©ricas e predizem uma sa√≠da, seja ela uma determinada classe ou um n√∫mero.\n",
    "\n",
    "Normalmente, o processo para treinar esses modelos consiste em:\n",
    "\n",
    "    1. Adquirir dados (que acreditamos ter potencial para prever *algo*)\n",
    "\n",
    "    2. Identificar caracter√≠sticas estat√≠sticas, anomalias e os tipos desses dados\n",
    "\n",
    "    3. Transformar os dados em uma cole√ß√£o de n√∫meros com alguma rela√ß√£o com *algo* que queremos prever\n",
    "    \n",
    "    4. Escolher um modelo de aprendizado que seja capaz de eventualmente prever esses dados\n",
    "\n",
    "    5. Medir a performance desse modelo\n",
    "\n",
    "    6. Melhorar a performance do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padr√£o de projeto em IA:\n",
    "\n",
    "Agora, veja o √≠ndice de um dos cap√≠tulos do livro 'Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](./imgs/handson_ml_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D√™ uma olhada agora nos componentes do ciclo de MLOps da Google, no livro 'Practical MLOps\n",
    "Operationalizing Machine Learning Models':\n",
    "\n",
    ">[(MLOps ou ML Ops √© um conjunto de pr√°ticas que visa implantar e manter modelos de machine learning em produ√ß√£o de forma confi√°vel e eficiente. A palavra √© um composto de \"machine learning\" e a pr√°tica de desenvolvimento cont√≠nuo de DevOps na √°rea de software.)](https://www.google.com/search?q=mlops&sxsrf=ALiCzsYlr6Lajbj_pnIRMp_EcUHZJYf8_A:1658366859510&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjBssX86Yj5AhXdSLgEHQ3CClsQ_AUoAXoECAIQAw&biw=1360&bih=699&dpr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/google_mlops.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por √∫ltimo, veja o ciclo de vida de solu√ß√µes de aprendizado de m√°quina, apresentado no livro 'Machine Learning Design Patterns Solutions to Common Challenges in Data Preparation, Model Building, and MLOps':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/ml_life_cycle_ml_design_patterns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway:\n",
    "\n",
    "E ent√£o? Notou algum padr√£o?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem, diante dos livros e tamb√©m de competi√ß√µes (como vou mostrar a seguir), existe uma forte tendencia no mercado e na academia de transformar a proposta, treino e predi√ß√£o de modelos de IA em uma *pipeline* autom√°tica, composta de:\n",
    "\n",
    "    1. EDA (an√°lise explorat√≥ria de dados, *exploratory data analysis*)\n",
    "\n",
    "    2. Engenharia de Caracter√≠sticas\n",
    "\n",
    "    3. Sele√ß√£o de Modelo(s)\n",
    "\n",
    "    4. Treino\n",
    "\n",
    "    5. Predi√ß√£o\n",
    "\n",
    "    6. Retreino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare a lista de passos acima com as imagens e com a lista de passos no in√≠cio dessa se√ß√£o. Estes passos s√£o a ess√™ncia (automatiz√°vel!) do aprendizado de m√°quina.\n",
    "\n",
    "### Seu papel ent√£o como pesquisador, desenvolvedor e competidor √© fazer isso t√£o r√°pido e t√£o bom quanto poss√≠vel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competindo no Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Vimos que *nos livros* esses m√©todos s√£o usados. Mas e no Kaggle?\n",
    "\n",
    "D√™ uma olhada r√°pida nas se√ß√µes [deste notebook](). N√£o se preocupe neste primeiro momento em entender os dados ou os resultados. O foco aqui √© na metodologia deste autor. Notou um padr√£o relacionado √† se√ß√£o anterior?\n",
    "\n",
    "No notebook, em linhas gerais, o autor:\n",
    "\n",
    "    1. Importou e visualizou distribui√ß√µes dos dados\n",
    "\n",
    "    2. Limpou e selecionou aqueles que mais importavam para seu contexto/problema\n",
    "\n",
    "    3. Escolheu n√£o UM mas DOZE modelos diferentes, sendo eles:\n",
    "        - Florestas aleat√≥rias:\n",
    "            1. Linear Regression, \n",
    "            2. Ridge Regression, \n",
    "            3. Support Vector Regression, \n",
    "            4. Random Forest Regressor, \n",
    "            5. Gradient Boosting Regressor, \n",
    "            6. AdaBoost Regressor, \n",
    "            7. XGBoost Regressor.\n",
    "        - Modelos Neurais Profundos:\n",
    "            9. Simple RNN, \n",
    "            10. LSTM, \n",
    "            11. Bidirectional RNN\n",
    "        - Transformers:\n",
    "            11. BERT\n",
    "\n",
    "    4. Treinou todos estes modelos \n",
    "\n",
    "    5. Previu as sa√≠das em banco de valida√ß√£o\n",
    "\n",
    "    6. Escolheu o melhor modelo e utilizou ele para submiss√£o.\n",
    "\n",
    "Tudo isso, em um notebook que executa por completo em 1789.1 segundos (30 minutos)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beleza, um monstro da IA. Como fa√ßo isso? Baby steps. Com certeza esse cara n√£o nasceu escrevendo notebooks Kaggle com 12 modelos treinados, ele aprendeu e realizou cada uma das etapas separadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Problemas em IA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eis algumas √°reas e problemas que modelos de IA s√£o utilizados para resolver:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/ml_tasks_huggingface.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como come√ßar?\n",
    "\n",
    "Qual modelo faz o que? Quando uso cada um? O que preciso para trein√°-los?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidentemente, n√£o existe resposta exata e completa para nenhuma destas perguntas. Mas assumindo o escopo dos problemas que buscamos resolver atualmente em competi√ß√µes de Kaggle, aqui est√£o alguns recursos e sugest√µes (üî®MARRETAS!) de onde eu comecei, que talvez possam te ajudar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. RTFD (READ THE FUCKING DOCS)\n",
    "\n",
    "Leia sempre as documenta√ß√µes. Grande parte das respostas √† suas perguntas v√£o estar descritas em exemplos e documenta√ß√µes de sites como o da biblioteca [Scikit-Learn](https://scikit-learn.org/stable/index.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sklearn LP](./imgs/sklearn_frontpage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J√° na sua p√°gina inicial a sklearn nos d√° algumas li√ß√µes:\n",
    "\n",
    "- Existem 2 tipos principais de problemas: Classifi√ß√£o e Regress√£o.\n",
    "- Muitas vezes n√£o temos etiquetas (labels) para saber o que deveriamos prever. Para isso, Clustering.\n",
    "- √Äs vezes temos dados demais (muitas dimens√µes) e precisaremos de m√©todos para reduz√≠-las (exemplo: PCA).\n",
    "- Sele√ß√£o de modelos √© importante e existem m√©todos autom√°ticos (mas lentos) para isso.\n",
    "- Preprocessamento (limpeza, normaliza√ß√£o e extra√ß√£o de caracter√≠sticas de dados) √© essencial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ent√£o, antes de desesperar ('Don't panic!' - The Hitchhiker's Guide to the Galaxy), tente buscar no Google: 'sklearn regression example', quando estiver com um problema de regress√£o. E claro, antes de abrir 327 abas da Wikipedia indo de \"Regress√£o\" at√© \"F√≠sica Qu√¢ntica\", considere executar passo a passo um exemplo da biblioteca sklearn. Voc√™ vai se surpreender com qu√£o simples √© usar as ferramentas de l√°!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forests e Ensembles (Boosting)\n",
    "\n",
    "> Florestas marreteiras d√£o baseline pra te ajudar a decidir se seu preprocessamento est√° minimamente aceit√°vel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Florestas aleat√≥rias s√£o bastante tendenciosas e podem sofrer com bancos de dados desbalanceados. Mas trein√°-las √© r√°pido, f√°cil e frequentemente √© a primeira na maioria das submiss√µes \"baseline\" em competi√ß√µes Kaggle.\n",
    "\n",
    "Elas recebem como entrada uma tabela em caracter√≠sticas em colunas, e cada entrada (inst√¢ncia de dados) em linhas, sempre num√©ricas. \n",
    "\n",
    "Logo, se voc√™ tem features categ√≥ricas (texto, por exemplo), vai precisar transform√°-las em n√∫meros de alguma forma!\n",
    "\n",
    "Como sa√≠da, estas redes normalmente possuem implementa√ß√µes para tarefas de regress√£o ou classifica√ß√£o. \n",
    "\n",
    "Aqui alguns links (com exemplos para classifica√ß√£o) de bibliotecas de Random Forests muito usadas:\n",
    "\n",
    "- [lightgbm.LGBMClassifier ‚Äî LightGBM 3.3.2.99 documentation](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n",
    "- [XGBoost Documentation ‚Äî xgboost 1.6.1 documentation](https://xgboost.readthedocs.io/en/stable/)\n",
    "- [sklearn.ensemble.RandomForestClassifier ‚Äî scikit-learn 1.1.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [sklearn.multiclass.OneVsRestClassifier ‚Äî scikit-learn 1.1.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)\n",
    "- [LightGBM Classifier in Python | Kaggle](https://www.kaggle.com/code/prashant111/lightgbm-classifier-in-python/notebook)\n",
    "\n",
    "\n",
    "Dica: XGBoost tem treino normalmente mais lento que o LGBM, e nem sempre tem uma performance melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perceptron Multicamadas (MLP)\n",
    "\n",
    "> Neur√¥nios s√£o dif√≠ceis de treinar mas podem abstrair padr√µes, diferente das florestas marreteiras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.neural_network.MLPClassifier ‚Äî scikit-learn 1.1.1 documentation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkkkkkk boa sorte, ainda n√£o tive tempo de escrever essa parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Redes Convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkkkkkk boa sorte, ainda n√£o tive tempo de escrever essa parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Outros m√©todos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkkkkkk boa sorte, ainda n√£o tive tempo de escrever essa parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erros comuns e como escapar deles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos de nomenclatura quais [tipos de erros existem](https://www.expii.com/t/types-of-error-overview-comparison-8112)?\n",
    "\n",
    "<div>\n",
    "    <img src=\"./imgs/types_of_error.jpeg\", height='520px'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui queremos diminuir os erros sistem√°ticos te√≥ricos (sele√ß√£o de modelos), observacionais (sele√ß√£o de features) e instrumentais (treinamento e emprego de modelos). Mas como?\n",
    "\n",
    "Na documenta√ß√£o da biblioteca sklearn, existe um artigo interessante sobre [erros comuns e pr√°ticas recomendadas](https://scikit-learn.org/stable/common_pitfalls.html), frequentemente discutidos em cursos sobre IA. Voc√™ pode ler com mais detalhes no link, mas alguns pontos importantes s√£o:\n",
    "\n",
    "- Preprocesse com pipelines, sempre da mesma maneira, para controlar melhor os ajustes que voc√™ aplica ao seu modelo.\n",
    "- Atente-se para separar bem a sa√≠da e entrada do modelo! \n",
    "- Controle as seeds aleat√≥rias para obter reproducibilidade.\n",
    "- Use valida√ß√£o cruzada para verificar com precis√£o a performance do seu modelo.\n",
    "\n",
    "√â importante tamb√©m conhecer alguns detalhes importantes ao se trabalhar com medidas e transforma√ß√µes estat√≠sticas, para se interpretar corretamente a sua EDA. Leia [neste documento](https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html) um relat√≥rio sobre interpreta√ß√£o de correla√ß√£o, escala, vari√¢ncia, entre outros. [Um outro artigo interessante na biblioteca sklearn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py) trata do impacto e comportamento da normaliza√ß√£o de escala e processamento de outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursos:\n",
    "\n",
    "CommonLit: EDA + (Most) NLP Techniquesüìö | Kaggle\n",
    "https://www.kaggle.com/code/utcarshagrawal/commonlit-eda-most-nlp-techniques/notebook\n",
    "\n",
    "List of datasets for machine-learning research - Wikipedia\n",
    "https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Human\n",
    "\n",
    "Outline of machine learning - Wikipedia\n",
    "https://en.wikipedia.org/wiki/Outline_of_machine_learning\n",
    "\n",
    "Models - Hugging Face\n",
    "https://huggingface.co/models?sort=downloads\n",
    "\n",
    "scikit-learn: machine learning in Python ‚Äî scikit-learn 1.1.1 documentation\n",
    "https://scikit-learn.org/stable/index.html\n",
    "\n",
    "10. Common pitfalls and recommended practices ‚Äî scikit-learn 1.1.1 documentation\n",
    "https://scikit-learn.org/stable/common_pitfalls.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dd76241fa2ee905525e0a1efacb16294be0e14843e7f10299cba718b3e5fb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
